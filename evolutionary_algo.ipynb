{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import sklearn.model_selection as skm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps in Evolutionary Strategy \n",
    "\"\"\"\n",
    "    1. Parent Selection : Select Parents from the population\n",
    "    2. Cross Over : Create Offsprings from parents : Uniform Cross Over p = 0.5\n",
    "    3. Mutation : Flip the bits of the offsprings with probability p = 0.3\n",
    "    4. Evaluation : Evaluate the fitness of the offsprings using the fitness function (Validation, NegCP, AIC, BIC)\n",
    "    5. Selection : Select the best offsprings to be the parents of the next generation\n",
    "\"\"\"\n",
    "\n",
    "# Parent Selection\n",
    "def parentSelection(population_size, total_parents) : \n",
    "    parent_feature_size = np.random.randint(1, population_size, total_parents)\n",
    "    parents = []\n",
    "    for size in parent_feature_size : \n",
    "        parent_vector = np.zeros(population_size, dtype = bool)\n",
    "        selected_indices = np.random.choice(population_size, size, replace=False)\n",
    "        parent_vector[selected_indices] = True\n",
    "        parents.append(parent_vector)\n",
    "    return np.array(parents)\n",
    "\n",
    "# Uniform Cross Over\n",
    "def uniformCrossOver(total_parents, probability, population_size, parents : np.ndarray) : \n",
    "    offspring = []\n",
    "    offspring_total = int(total_parents / 2)\n",
    "    \n",
    "    for i in range(offspring_total) : \n",
    "        \"\"\"\n",
    "            Uniform Cross Over : \n",
    "            Select J bit from Parent 1 with probability p\n",
    "            Select J bit from Parent 2 with probability 1-p\n",
    "        \"\"\"\n",
    "        parent_1 = parents[i]\n",
    "        parent_2 = parents[i+5]\n",
    "        offspring_vector = np.zeros(population_size, dtype = bool)\n",
    "    \n",
    "        for j in range(population_size) : \n",
    "            if np.random.rand() < probability : \n",
    "                offspring_vector[j] = parent_1[j]\n",
    "            else : \n",
    "                offspring_vector[j] = parent_2[j]\n",
    "        offspring.append(offspring_vector)\n",
    "    return np.array(offspring)\n",
    "\n",
    "# Mutation\n",
    "def mutation(probability, total_parents, population_size, offspring) : \n",
    "    offspring_total = int(total_parents/2)\n",
    "    for i in range(offspring_total) : \n",
    "        mutation_vector = offspring[i]\n",
    "        for j in range(population_size) : \n",
    "            if np.random.rand() < probability : \n",
    "                mutation_vector[j] = not mutation_vector[j]\n",
    "        offspring[i] = mutation_vector\n",
    "    return offspring\n",
    "\n",
    "\n",
    "# Evaluation : Validation Set Approach\n",
    "def evaluation(new_population, data, response, population_columns, training_size=0.8, random_state=42):\n",
    "    fitness = []\n",
    "    for i in range(len(new_population)):\n",
    "        design = MS(population_columns[i])\n",
    "        data_train, data_test = skm.train_test_split(data, train_size=0.8, random_state=42)\n",
    "        y_train = data_train[response]\n",
    "        y_test = data_test[response]\n",
    "        x_train = design.fit_transform(data_train)\n",
    "        x_test = design.transform(data_test)\n",
    "        model = sm.OLS(y_train, x_train).fit()\n",
    "        predicted = model.predict(x_test)\n",
    "        rss = model.aic\n",
    "        fitness.append(rss)\n",
    "    top_10 = np.argsort(fitness)\n",
    "    survival_selection = new_population[top_10[:10]]\n",
    "    return survival_selection\n",
    "   \n",
    "def evaluation_best(new_population, data, response, population_columns, training_size=0.8, random_state=42):\n",
    "    fitness = []\n",
    "    for i in range(len(new_population)):\n",
    "        design = MS(population_columns[i])\n",
    "        data_train, data_test = skm.train_test_split(data, train_size=0.8, random_state=42)\n",
    "        y_train = data_train[response]\n",
    "        y_test = data_test[response]\n",
    "        x_train = design.fit_transform(data_train)\n",
    "        x_test = design.transform(data_test)\n",
    "        model = sm.OLS(y_train, x_train).fit()\n",
    "        predicted = model.predict(x_test)\n",
    "        rss = model.aic\n",
    "        fitness.append(rss)\n",
    "    best_idx = np.argmin(fitness)\n",
    "    survival_selection = new_population[best_idx]\n",
    "    return survival_selection, fitness[best_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"Hitters\")\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation :  0\n",
      "Generation :  10\n",
      "Generation :  20\n",
      "Generation :  30\n",
      "Generation :  40\n",
      "Best Individual :  Index(['AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', 'Walks', 'CAtBat', 'CHits',\n",
      "       'CHmRun', 'CRuns', 'CRBI', 'CWalks', 'League', 'Division', 'PutOuts',\n",
      "       'Assists', 'Errors', 'NewLeague'],\n",
      "      dtype='object')\n",
      "Best Fitness :  3018.1186773189916\n"
     ]
    }
   ],
   "source": [
    "# Initializing the Population\n",
    "response = \"Salary\"\n",
    "population = data.columns.drop(response)\n",
    "population_size = len(population)\n",
    "total_parents = 10\n",
    "evolve = 50\n",
    "\n",
    "for i in range(evolve) :\n",
    "    parents = parentSelection(population_size, total_parents)\n",
    "    offspring = uniformCrossOver(total_parents, 0.5, population_size, parents)\n",
    "    offspring_mutated = mutation(0.3, total_parents, population_size, offspring)\n",
    "    new_population = np.vstack([parents, offspring_mutated])\n",
    "    population_columns = [population[new_population[i]] for i in range(len(new_population))]\n",
    "    good_individual = evaluation(new_population, data, response, population_columns=population_columns)\n",
    "    parents = good_individual\n",
    "    if i % 10 == 0 :\n",
    "        print(\"Generation : \", i)\n",
    "    \n",
    "best_individual, best_fitness = evaluation_best(parents, data, response, population_columns=population_columns)\n",
    "print(\"Best Individual : \", population[best_individual])\n",
    "print(\"Best Fitness : \", best_fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Salary</td>      <th>  R-squared:         </th> <td>   0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   16.30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 07 Mar 2025</td> <th>  Prob (F-statistic):</th> <td>1.98e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:48:39</td>     <th>  Log-Likelihood:    </th> <td> -1876.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   263</td>      <th>  AIC:               </th> <td>   3790.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   244</td>      <th>  BIC:               </th> <td>   3858.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>    <td>  148.2187</td> <td>   73.595</td> <td>    2.014</td> <td> 0.045</td> <td>    3.256</td> <td>  293.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AtBat</th>        <td>   -1.9509</td> <td>    0.624</td> <td>   -3.125</td> <td> 0.002</td> <td>   -3.181</td> <td>   -0.721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hits</th>         <td>    7.4395</td> <td>    2.363</td> <td>    3.148</td> <td> 0.002</td> <td>    2.785</td> <td>   12.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HmRun</th>        <td>    4.3449</td> <td>    6.190</td> <td>    0.702</td> <td> 0.483</td> <td>   -7.847</td> <td>   16.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Runs</th>         <td>   -2.3312</td> <td>    2.971</td> <td>   -0.785</td> <td> 0.433</td> <td>   -8.183</td> <td>    3.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RBI</th>          <td>   -1.0670</td> <td>    2.595</td> <td>   -0.411</td> <td> 0.681</td> <td>   -6.178</td> <td>    4.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Walks</th>        <td>    6.2196</td> <td>    1.825</td> <td>    3.409</td> <td> 0.001</td> <td>    2.626</td> <td>    9.813</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CAtBat</th>       <td>   -0.1887</td> <td>    0.120</td> <td>   -1.572</td> <td> 0.117</td> <td>   -0.425</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHits</th>        <td>    0.1636</td> <td>    0.665</td> <td>    0.246</td> <td> 0.806</td> <td>   -1.146</td> <td>    1.474</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHmRun</th>       <td>   -0.1517</td> <td>    1.612</td> <td>   -0.094</td> <td> 0.925</td> <td>   -3.328</td> <td>    3.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRuns</th>        <td>    1.4716</td> <td>    0.747</td> <td>    1.971</td> <td> 0.050</td> <td>    0.001</td> <td>    2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRBI</th>         <td>    0.8021</td> <td>    0.691</td> <td>    1.161</td> <td> 0.247</td> <td>   -0.559</td> <td>    2.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CWalks</th>       <td>   -0.8124</td> <td>    0.327</td> <td>   -2.481</td> <td> 0.014</td> <td>   -1.457</td> <td>   -0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>League[N]</th>    <td>   63.7503</td> <td>   79.006</td> <td>    0.807</td> <td> 0.421</td> <td>  -91.871</td> <td>  219.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Division[W]</th>  <td> -116.0404</td> <td>   40.188</td> <td>   -2.887</td> <td> 0.004</td> <td> -195.201</td> <td>  -36.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PutOuts</th>      <td>    0.2827</td> <td>    0.077</td> <td>    3.661</td> <td> 0.000</td> <td>    0.131</td> <td>    0.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Assists</th>      <td>    0.3755</td> <td>    0.220</td> <td>    1.705</td> <td> 0.089</td> <td>   -0.058</td> <td>    0.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Errors</th>       <td>   -3.2940</td> <td>    4.377</td> <td>   -0.753</td> <td> 0.452</td> <td>  -11.915</td> <td>    5.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NewLeague[N]</th> <td>  -24.3989</td> <td>   78.843</td> <td>   -0.309</td> <td> 0.757</td> <td> -179.698</td> <td>  130.901</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>88.911</td> <th>  Durbin-Watson:     </th> <td>   2.021</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 466.454</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.257</td> <th>  Prob(JB):          </th> <td>5.14e-102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.021</td> <th>  Cond. No.          </th> <td>2.07e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.07e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Salary      & \\textbf{  R-squared:         } &     0.546   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.512   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     16.30   \\\\\n",
       "\\textbf{Date:}             & Fri, 07 Mar 2025 & \\textbf{  Prob (F-statistic):} &  1.98e-32   \\\\\n",
       "\\textbf{Time:}             &     14:48:39     & \\textbf{  Log-Likelihood:    } &   -1876.2   \\\\\n",
       "\\textbf{No. Observations:} &         263      & \\textbf{  AIC:               } &     3790.   \\\\\n",
       "\\textbf{Df Residuals:}     &         244      & \\textbf{  BIC:               } &     3858.   \\\\\n",
       "\\textbf{Df Model:}         &          18      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                      & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{intercept}    &     148.2187  &       73.595     &     2.014  &         0.045        &        3.256    &      293.182     \\\\\n",
       "\\textbf{AtBat}        &      -1.9509  &        0.624     &    -3.125  &         0.002        &       -3.181    &       -0.721     \\\\\n",
       "\\textbf{Hits}         &       7.4395  &        2.363     &     3.148  &         0.002        &        2.785    &       12.094     \\\\\n",
       "\\textbf{HmRun}        &       4.3449  &        6.190     &     0.702  &         0.483        &       -7.847    &       16.537     \\\\\n",
       "\\textbf{Runs}         &      -2.3312  &        2.971     &    -0.785  &         0.433        &       -8.183    &        3.521     \\\\\n",
       "\\textbf{RBI}          &      -1.0670  &        2.595     &    -0.411  &         0.681        &       -6.178    &        4.044     \\\\\n",
       "\\textbf{Walks}        &       6.2196  &        1.825     &     3.409  &         0.001        &        2.626    &        9.813     \\\\\n",
       "\\textbf{CAtBat}       &      -0.1887  &        0.120     &    -1.572  &         0.117        &       -0.425    &        0.048     \\\\\n",
       "\\textbf{CHits}        &       0.1636  &        0.665     &     0.246  &         0.806        &       -1.146    &        1.474     \\\\\n",
       "\\textbf{CHmRun}       &      -0.1517  &        1.612     &    -0.094  &         0.925        &       -3.328    &        3.024     \\\\\n",
       "\\textbf{CRuns}        &       1.4716  &        0.747     &     1.971  &         0.050        &        0.001    &        2.942     \\\\\n",
       "\\textbf{CRBI}         &       0.8021  &        0.691     &     1.161  &         0.247        &       -0.559    &        2.163     \\\\\n",
       "\\textbf{CWalks}       &      -0.8124  &        0.327     &    -2.481  &         0.014        &       -1.457    &       -0.167     \\\\\n",
       "\\textbf{League[N]}    &      63.7503  &       79.006     &     0.807  &         0.421        &      -91.871    &      219.371     \\\\\n",
       "\\textbf{Division[W]}  &    -116.0404  &       40.188     &    -2.887  &         0.004        &     -195.201    &      -36.880     \\\\\n",
       "\\textbf{PutOuts}      &       0.2827  &        0.077     &     3.661  &         0.000        &        0.131    &        0.435     \\\\\n",
       "\\textbf{Assists}      &       0.3755  &        0.220     &     1.705  &         0.089        &       -0.058    &        0.809     \\\\\n",
       "\\textbf{Errors}       &      -3.2940  &        4.377     &    -0.753  &         0.452        &      -11.915    &        5.327     \\\\\n",
       "\\textbf{NewLeague[N]} &     -24.3989  &       78.843     &    -0.309  &         0.757        &     -179.698    &      130.901     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 88.911 & \\textbf{  Durbin-Watson:     } &     2.021  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   466.454  \\\\\n",
       "\\textbf{Skew:}          &  1.257 & \\textbf{  Prob(JB):          } & 5.14e-102  \\\\\n",
       "\\textbf{Kurtosis:}      &  9.021 & \\textbf{  Cond. No.          } &  2.07e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.07e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Salary   R-squared:                       0.546\n",
       "Model:                            OLS   Adj. R-squared:                  0.512\n",
       "Method:                 Least Squares   F-statistic:                     16.30\n",
       "Date:                Fri, 07 Mar 2025   Prob (F-statistic):           1.98e-32\n",
       "Time:                        14:48:39   Log-Likelihood:                -1876.2\n",
       "No. Observations:                 263   AIC:                             3790.\n",
       "Df Residuals:                     244   BIC:                             3858.\n",
       "Df Model:                          18                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "intercept      148.2187     73.595      2.014      0.045       3.256     293.182\n",
       "AtBat           -1.9509      0.624     -3.125      0.002      -3.181      -0.721\n",
       "Hits             7.4395      2.363      3.148      0.002       2.785      12.094\n",
       "HmRun            4.3449      6.190      0.702      0.483      -7.847      16.537\n",
       "Runs            -2.3312      2.971     -0.785      0.433      -8.183       3.521\n",
       "RBI             -1.0670      2.595     -0.411      0.681      -6.178       4.044\n",
       "Walks            6.2196      1.825      3.409      0.001       2.626       9.813\n",
       "CAtBat          -0.1887      0.120     -1.572      0.117      -0.425       0.048\n",
       "CHits            0.1636      0.665      0.246      0.806      -1.146       1.474\n",
       "CHmRun          -0.1517      1.612     -0.094      0.925      -3.328       3.024\n",
       "CRuns            1.4716      0.747      1.971      0.050       0.001       2.942\n",
       "CRBI             0.8021      0.691      1.161      0.247      -0.559       2.163\n",
       "CWalks          -0.8124      0.327     -2.481      0.014      -1.457      -0.167\n",
       "League[N]       63.7503     79.006      0.807      0.421     -91.871     219.371\n",
       "Division[W]   -116.0404     40.188     -2.887      0.004    -195.201     -36.880\n",
       "PutOuts          0.2827      0.077      3.661      0.000       0.131       0.435\n",
       "Assists          0.3755      0.220      1.705      0.089      -0.058       0.809\n",
       "Errors          -3.2940      4.377     -0.753      0.452     -11.915       5.327\n",
       "NewLeague[N]   -24.3989     78.843     -0.309      0.757    -179.698     130.901\n",
       "==============================================================================\n",
       "Omnibus:                       88.911   Durbin-Watson:                   2.021\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              466.454\n",
       "Skew:                           1.257   Prob(JB):                    5.14e-102\n",
       "Kurtosis:                       9.021   Cond. No.                     2.07e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.07e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = population[best_individual]\n",
    "design = MS(cols)\n",
    "x = design.fit_transform(data)\n",
    "y = data[response]\n",
    "model = sm.OLS(y, x).fit()\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci-env",
   "language": "python",
   "name": "datasci-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
